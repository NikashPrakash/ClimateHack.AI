{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClimateHack.AI 2023: Training a Basic Model\n",
    "\n",
    "Thank you for participating in ClimateHack.AI 2023! ðŸŒ\n",
    "\n",
    "Your contributions could help cut carbon emissions by up to 100 kilotonnes per year in Great Britain alone. We look forward to seeing what you build over the course of the competition!\n",
    "\n",
    "In this Jupyter notebook, you will hopefully train your first model for the challenge using historical solar PV data and HRV satellite imagery.\n",
    "\n",
    "For more detailed information on the challenge, see the [DOXA AI competition page](https://doxaai.com/competition/climatehackai-2023/overview). ðŸ˜Ž"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing packages\n",
    "\n",
    "Before you can get started, you will need to install a number of packages to allow you to work with the data and submit to the platform. If you do not already have these packages installed, you can uncomment the lines below to do so! You will also need to [install PyTorch](https://pytorch.org/get-started/locally/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xarray in c:\\users\\nikpr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2024.2.0)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\nikpr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xarray) (1.25.0)\n",
      "Requirement already satisfied: packaging>=22 in c:\\users\\nikpr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xarray) (24.0)\n",
      "Requirement already satisfied: pandas>=1.5 in c:\\users\\nikpr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xarray) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nikpr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.5->xarray) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nikpr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.5->xarray) (2022.2.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\nikpr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.5->xarray) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nikpr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5->xarray) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -harset-normalizer (c:\\users\\nikpr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\nikpr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -harset-normalizer (c:\\users\\nikpr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\nikpr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "DEPRECATION: pyitlib 0.2.2 has a non-standard dependency specifier pandas>=0.20.2numpy>=1.9.2. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyitlib or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "%pip install  xarray\n",
    "# %pip install -U doxa-cli "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages\n",
    "\n",
    "Here, we import a number of packages we will need to train our first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import uuid\n",
    "from typing import Any, Dict, List, Optional\n",
    "import torch\n",
    "import xarray\n",
    "from google.cloud import aiplatform, storage\n",
    "from google_cloud_pipeline_components.preview.automl.forecasting import \\\n",
    "    utils as automl_forecasting_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"solar-pv-yeilds\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}\n",
    "REGION = \"us-central1\" \n",
    "# ! gcloud auth login\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating your submission directory\n",
    "\n",
    "If you cloned [this repository](https://github.com/climatehackai/getting-started-2023) straight from GitHub, you will already have all the files you need, but if you are running this notebook using Google Colab, we just need to download a couple extra files to create a fresh submission directory that you will soon hopefully be in a position to upload to the platform as part of your first competition submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"submission\"):\n",
    "    os.makedirs(\"submission\", exist_ok=True)\n",
    "\n",
    "    !curl -L https://raw.githubusercontent.com/climatehackai/getting-started-2023/main/submission/competition.py --output submission/competition.py\n",
    "    !curl -L https://raw.githubusercontent.com/climatehackai/getting-started-2023/main/submission/doxa.yaml --output submission/doxa.yaml\n",
    "    !curl -L https://raw.githubusercontent.com/climatehackai/getting-started-2023/main/submission/model.py --output submission/model.py\n",
    "    !curl -L https://raw.githubusercontent.com/climatehackai/getting-started-2023/main/submission/run.py --output submission/run.py\n",
    "    !curl -L https://raw.githubusercontent.com/climatehackai/getting-started-2023/main/indices.json --output indices.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading a month of data\n",
    "\n",
    "While streaming the Zarr-format datasets directly from Hugging Face was adequate for some initial data exploration in `1_data.ipynb`, it most likely will not be fast enough in training. Since there is so much data available, we can get started just by downloading a single month of PV and HRV satellite imagery data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 14 1300k   14  192k    0     0   877k      0  0:00:01 --:--:--  0:00:01  884k\n",
      "100 1300k  100 1300k    0     0  4212k      0 --:--:-- --:--:-- --:--:-- 4235k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  1122  100  1122    0     0  11699      0 --:--:-- --:--:-- --:--:-- 12329\n",
      "\n",
      "  7 74.3M    7 5976k    0     0  7279k      0  0:00:10 --:--:--  0:00:10 7279k\n",
      " 29 74.3M   29 21.7M    0     0  11.9M      0  0:00:06  0:00:01  0:00:05 15.9M\n",
      " 48 74.3M   48 36.1M    0     0  9763k      0  0:00:07  0:00:03  0:00:04 10.2M\n",
      " 48 74.3M   48 36.1M    0     0  8513k      0  0:00:08  0:00:04  0:00:04 8802k\n",
      " 59 74.3M   59 44.2M    0     0  9404k      0  0:00:08  0:00:04  0:00:04 9839k\n",
      " 82 74.3M   82 61.3M    0     0  10.5M      0  0:00:07  0:00:05  0:00:02 11.1M\n",
      "100 74.3M  100 74.3M    0     0  11.2M      0  0:00:06  0:00:06 --:--:-- 10.9M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  1192  100  1192    0     0  11464      0 --:--:-- --:--:-- --:--:-- 11801\n",
      "\n",
      "  0 4049M    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 4049M    0 11.5M    0     0   9.9M      0  0:06:48  0:00:01  0:06:47 16.4M\n",
      "  0 4049M    0 26.6M    0     0  12.2M      0  0:05:29  0:00:02  0:05:27 15.6M\n",
      "  1 4049M    1 43.9M    0     0  13.8M      0  0:04:52  0:00:03  0:04:49 16.2M\n",
      "  1 4049M    1 59.3M    0     0  14.1M      0  0:04:45  0:00:04  0:04:41 15.9M\n",
      "  1 4049M    1 63.5M    0     0  12.3M      0  0:05:29  0:00:05  0:05:24 13.5M\n",
      "  1 4049M    1 78.8M    0     0  12.7M      0  0:05:17  0:00:06  0:05:11 13.4M\n",
      "  2 4049M    2 92.5M    0     0  12.9M      0  0:05:13  0:00:07  0:05:06 13.1M\n",
      "  2 4049M    2  110M    0     0  13.4M      0  0:05:00  0:00:08  0:04:52 13.2M\n",
      "  3 4049M    3  126M    0     0  13.7M      0  0:04:53  0:00:09  0:04:44 13.4M\n",
      "  3 4049M    3  145M    0     0  14.3M      0  0:04:42  0:00:10  0:04:32 16.3M\n",
      "  4 4049M    4  164M    0     0  14.7M      0  0:04:34  0:00:11  0:04:23 17.2M\n",
      "  4 4049M    4  180M    0     0  14.8M      0  0:04:32  0:00:12  0:04:20 17.6M\n",
      "  4 4049M    4  194M    0     0  14.7M      0  0:04:34  0:00:13  0:04:21 16.9M\n",
      "  5 4049M    5  208M    0     0  14.6M      0  0:04:35  0:00:14  0:04:21 16.3M\n",
      "  5 4049M    5  220M    0     0  14.5M      0  0:04:38  0:00:15  0:04:23 15.0M\n",
      "  5 4049M    5  232M    0     0  14.3M      0  0:04:41  0:00:16  0:04:25 13.5M\n",
      "  6 4049M    6  244M    0     0  14.2M      0  0:04:43  0:00:17  0:04:26 12.7M\n",
      "  6 4049M    6  256M    0     0  14.0M      0  0:04:47  0:00:18  0:04:29 12.2M\n",
      "  6 4049M    6  269M    0     0  14.0M      0  0:04:47  0:00:19  0:04:28 12.3M\n",
      "  6 4049M    6  282M    0     0  13.9M      0  0:04:50  0:00:20  0:04:30 12.1M\n",
      "  7 4049M    7  291M    0     0  13.7M      0  0:04:54  0:00:21  0:04:33 11.7M\n",
      "  7 4049M    7  303M    0     0  13.6M      0  0:04:55  0:00:22  0:04:33 11.6M\n",
      "  7 4049M    7  316M    0     0  13.6M      0  0:04:56  0:00:23  0:04:33 12.1M\n",
      "  8 4049M    8  328M    0     0  13.5M      0  0:04:59  0:00:24  0:04:35 11.5M\n",
      "  8 4049M    8  344M    0     0  13.6M      0  0:04:56  0:00:25  0:04:31 12.5M\n",
      "  8 4049M    8  363M    0     0  13.8M      0  0:04:51  0:00:26  0:04:25 14.3M\n",
      "  9 4049M    9  380M    0     0  14.0M      0  0:04:49  0:00:27  0:04:22 15.4M\n",
      "  9 4049M    9  382M    0     0  13.5M      0  0:04:59  0:00:28  0:04:31 12.8M\n",
      "  9 4049M    9  382M    0     0  13.0M      0  0:05:10  0:00:29  0:04:41 10.7M\n",
      "  9 4049M    9  388M    0     0  12.6M      0  0:05:19  0:00:30  0:04:49 8351k\n",
      "  9 4049M    9  388M    0     0  12.2M      0  0:05:29  0:00:31  0:04:58 4781k\n",
      "  9 4049M    9  388M    0     0  11.9M      0  0:05:38  0:00:32  0:05:06 1544k\n",
      "  9 4049M    9  402M    0     0  12.1M      0  0:05:33  0:00:33  0:05:00 4256k\n",
      " 10 4049M   10  418M    0     0  12.2M      0  0:05:31  0:00:34  0:04:57 7457k\n",
      " 10 4049M   10  428M    0     0  12.1M      0  0:05:32  0:00:35  0:04:57 8871k\n",
      " 10 4049M   10  444M    0     0  12.2M      0  0:05:29  0:00:36  0:04:53 12.2M\n",
      " 11 4049M   11  462M    0     0  12.4M      0  0:05:25  0:00:37  0:04:48 15.7M\n",
      " 11 4049M   11  467M    0     0  12.2M      0  0:05:31  0:00:38  0:04:53 12.8M\n",
      " 11 4049M   11  481M    0     0  12.2M      0  0:05:29  0:00:39  0:04:50 12.6M\n",
      " 12 4049M   12  492M    0     0  12.0M      0  0:05:37  0:00:41  0:04:56 11.0M\n",
      " 12 4049M   12  492M    0     0  11.8M      0  0:05:42  0:00:41  0:05:01 9023k\n",
      " 12 4049M   12  501M    0     0  11.8M      0  0:05:40  0:00:42  0:04:58 8016k\n",
      " 12 4049M   12  519M    0     0  12.0M      0  0:05:36  0:00:43  0:04:53 10.5M\n",
      " 13 4049M   13  538M    0     0  12.1M      0  0:05:32  0:00:44  0:04:48 11.3M\n",
      " 13 4049M   13  553M    0     0  12.2M      0  0:05:30  0:00:45  0:04:45 14.6M\n",
      " 13 4049M   13  557M    0     0  12.0M      0  0:05:36  0:00:46  0:04:50 14.1M\n",
      " 14 4049M   14  570M    0     0  12.0M      0  0:05:35  0:00:47  0:04:48 13.6M\n",
      " 14 4049M   14  589M    0     0  12.2M      0  0:05:30  0:00:48  0:04:42 13.8M\n",
      " 15 4049M   15  609M    0     0  12.3M      0  0:05:26  0:00:49  0:04:37 14.1M\n",
      " 15 4049M   15  629M    0     0  12.5M      0  0:05:22  0:00:50  0:04:32 15.3M\n",
      " 16 4049M   16  648M    0     0  12.6M      0  0:05:19  0:00:51  0:04:28 18.5M\n",
      " 16 4049M   16  664M    0     0  12.7M      0  0:05:18  0:00:52  0:04:26 18.6M\n",
      " 16 4049M   16  684M    0     0  12.8M      0  0:05:14  0:00:53  0:04:21 19.0M\n",
      " 17 4049M   17  699M    0     0  12.9M      0  0:05:13  0:00:54  0:04:19 18.0M\n",
      " 17 4049M   17  703M    0     0  12.6M      0  0:05:19  0:00:55  0:04:24 14.0M\n",
      " 17 4049M   17  703M    0     0  12.4M      0  0:05:23  0:00:56  0:04:27 10.7M\n",
      " 17 4049M   17  706M    0     0  12.2M      0  0:05:29  0:00:57  0:04:32 8126k\n",
      " 17 4049M   17  706M    0     0  12.0M      0  0:05:35  0:00:58  0:04:37 4083k\n",
      " 17 4049M   17  707M    0     0  11.9M      0  0:05:38  0:00:59  0:04:39 1721k\n",
      " 17 4049M   17  724M    0     0  12.0M      0  0:05:36  0:01:00  0:04:36 4545k\n",
      " 18 4049M   18  731M    0     0  11.8M      0  0:05:41  0:01:01  0:04:40 5360k\n",
      " 18 4049M   18  731M    0     0  11.6M      0  0:05:46  0:01:02  0:04:44 5101k\n",
      " 18 4049M   18  741M    0     0  11.7M      0  0:05:44  0:01:03  0:04:41 7889k\n",
      " 18 4049M   18  760M    0     0  11.8M      0  0:05:41  0:01:04  0:04:37 10.5M\n",
      " 19 4049M   19  778M    0     0  11.9M      0  0:05:39  0:01:05  0:04:34 10.7M\n",
      " 19 4049M   19  795M    0     0  12.0M      0  0:05:36  0:01:06  0:04:30 14.3M\n",
      " 20 4049M   20  810M    0     0  12.0M      0  0:05:35  0:01:07  0:04:28 17.4M\n",
      " 20 4049M   20  827M    0     0  12.1M      0  0:05:33  0:01:08  0:04:25 17.0M\n",
      " 20 4049M   20  840M    0     0  12.1M      0  0:05:33  0:01:09  0:04:24 16.0M\n",
      " 21 4049M   21  860M    0     0  12.2M      0  0:05:30  0:01:10  0:04:20 16.4M\n",
      " 21 4049M   21  877M    0     0  12.3M      0  0:05:28  0:01:11  0:04:17 16.3M\n",
      " 22 4049M   22  894M    0     0  12.3M      0  0:05:26  0:01:12  0:04:14 16.7M\n",
      " 22 4049M   22  915M    0     0  12.5M      0  0:05:23  0:01:13  0:04:10 17.6M\n",
      " 22 4049M   22  927M    0     0  12.4M      0  0:05:26  0:01:14  0:04:12 15.5M\n",
      " 22 4049M   22  927M    0     0  12.2M      0  0:05:30  0:01:15  0:04:15 12.1M\n",
      " 23 4049M   23  937M    0     0  12.2M      0  0:05:29  0:01:16  0:04:13 11.7M\n",
      " 23 4049M   23  953M    0     0  12.3M      0  0:05:27  0:01:17  0:04:10 11.7M\n",
      " 24 4049M   24  973M    0     0  12.4M      0  0:05:25  0:01:18  0:04:07 11.4M\n",
      " 24 4049M   24  991M    0     0  12.5M      0  0:05:23  0:01:19  0:04:04 14.4M\n",
      " 24 4049M   24 1004M    0     0  12.4M      0  0:05:26  0:01:20  0:04:06 14.7M\n",
      " 24 4049M   24 1004M    0     0  12.3M      0  0:05:29  0:01:21  0:04:08 12.4M\n",
      " 25 4049M   25 1015M    0     0  12.3M      0  0:05:27  0:01:22  0:04:05 12.4M\n",
      " 25 4049M   25 1034M    0     0  12.4M      0  0:05:25  0:01:23  0:04:02 12.3M\n",
      " 25 4049M   25 1051M    0     0  12.4M      0  0:05:24  0:01:24  0:04:00 12.0M\n",
      " 26 4049M   26 1070M    0     0  12.5M      0  0:05:22  0:01:25  0:03:57 15.1M\n",
      " 26 4049M   26 1087M    0     0  12.6M      0  0:05:21  0:01:26  0:03:55 18.1M\n",
      " 27 4049M   27 1104M    0     0  12.6M      0  0:05:19  0:01:27  0:03:52 17.8M\n",
      " 27 4049M   27 1114M    0     0  12.5M      0  0:05:22  0:01:28  0:03:54 14.2M\n",
      " 27 4049M   27 1114M    0     0  12.4M      0  0:05:25  0:01:29  0:03:56 11.3M\n",
      " 27 4049M   27 1121M    0     0  12.3M      0  0:05:27  0:01:30  0:03:57 9612k\n",
      " 27 4049M   27 1130M    0     0  12.4M      0  0:05:26  0:01:31  0:03:55 8903k\n",
      " 28 4049M   28 1153M    0     0  12.5M      0  0:05:23  0:01:32  0:03:51 9914k\n",
      " 29 4049M   29 1179M    0     0  12.6M      0  0:05:19  0:01:33  0:03:46 14.7M\n",
      " 29 4049M   29 1203M    0     0  12.7M      0  0:05:16  0:01:34  0:03:42 19.8M\n",
      " 30 4049M   30 1231M    0     0  12.9M      0  0:05:13  0:01:35  0:03:38 23.9M\n",
      " 30 4049M   30 1248M    0     0  12.9M      0  0:05:12  0:01:36  0:03:36 23.3M\n",
      " 31 4049M   31 1265M    0     0  13.0M      0  0:05:11  0:01:37  0:03:34 22.3M\n",
      " 31 4049M   31 1285M    0     0  13.0M      0  0:05:09  0:01:38  0:03:31 21.3M\n",
      " 32 4049M   32 1305M    0     0  13.1M      0  0:05:07  0:01:39  0:03:28 20.4M\n",
      " 32 4049M   32 1323M    0     0  13.2M      0  0:05:06  0:01:40  0:03:26 18.6M\n",
      " 32 4049M   32 1329M    0     0  13.1M      0  0:05:09  0:01:41  0:03:28 15.3M\n",
      " 32 4049M   32 1329M    0     0  12.9M      0  0:05:12  0:01:42  0:03:30 12.1M\n",
      " 33 4049M   33 1346M    0     0  13.0M      0  0:05:10  0:01:43  0:03:27 12.2M\n",
      " 33 4049M   33 1367M    0     0  13.1M      0  0:05:08  0:01:44  0:03:24 12.2M\n",
      " 34 4049M   34 1389M    0     0  13.2M      0  0:05:06  0:01:45  0:03:21 13.2M\n",
      " 34 4049M   34 1406M    0     0  13.2M      0  0:05:05  0:01:46  0:03:19 16.4M\n",
      " 35 4049M   35 1428M    0     0  13.3M      0  0:05:03  0:01:47  0:03:16 20.9M\n",
      " 35 4049M   35 1450M    0     0  13.4M      0  0:05:01  0:01:48  0:03:13 20.7M\n",
      " 36 4049M   36 1466M    0     0  13.4M      0  0:05:01  0:01:49  0:03:12 19.8M\n",
      " 36 4049M   36 1485M    0     0  13.4M      0  0:05:00  0:01:50  0:03:10 19.1M\n",
      " 37 4049M   37 1504M    0     0  13.5M      0  0:04:59  0:01:51  0:03:08 19.5M\n",
      " 37 4049M   37 1522M    0     0  13.5M      0  0:04:58  0:01:52  0:03:06 18.8M\n",
      " 38 4049M   38 1539M    0     0  13.6M      0  0:04:57  0:01:53  0:03:04 17.7M\n",
      " 38 4049M   38 1553M    0     0  13.5M      0  0:04:59  0:01:54  0:03:05 15.4M\n",
      " 38 4049M   38 1556M    0     0  13.5M      0  0:04:59  0:01:55  0:03:04 14.3M\n",
      " 38 4049M   38 1576M    0     0  13.5M      0  0:04:58  0:01:56  0:03:02 14.3M\n",
      " 38 4049M   38 1578M    0     0  13.4M      0  0:05:00  0:01:57  0:03:03 10.9M\n",
      " 39 4049M   39 1583M    0     0  13.4M      0  0:05:02  0:01:58  0:03:04 9039k\n",
      " 39 4049M   39 1604M    0     0  13.4M      0  0:05:00  0:01:59  0:03:01 11.5M\n",
      " 40 4049M   40 1622M    0     0  13.4M      0  0:05:00  0:02:00  0:03:00 12.7M\n",
      " 40 4049M   40 1643M    0     0  13.5M      0  0:04:58  0:02:01  0:02:57 13.3M\n",
      " 41 4049M   41 1664M    0     0  13.6M      0  0:04:57  0:02:02  0:02:55 17.8M\n",
      " 41 4049M   41 1677M    0     0  13.5M      0  0:04:59  0:02:04  0:02:55 15.8M\n",
      " 41 4049M   41 1677M    0     0  13.4M      0  0:05:01  0:02:04  0:02:57 12.9M\n",
      " 41 4049M   41 1684M    0     0  13.4M      0  0:05:00  0:02:05  0:02:55 12.8M\n",
      " 42 4049M   42 1704M    0     0  13.5M      0  0:04:59  0:02:06  0:02:53 12.2M\n",
      " 42 4049M   42 1727M    0     0  13.5M      0  0:04:58  0:02:07  0:02:51 12.6M\n",
      " 43 4049M   43 1748M    0     0  13.6M      0  0:04:56  0:02:08  0:02:48 17.5M\n",
      " 43 4049M   43 1769M    0     0  13.6M      0  0:04:55  0:02:09  0:02:46 21.3M\n",
      " 44 4049M   44 1790M    0     0  13.7M      0  0:04:54  0:02:10  0:02:44 21.1M\n",
      " 44 4049M   44 1813M    0     0  13.8M      0  0:04:52  0:02:11  0:02:41 21.7M\n",
      " 45 4049M   45 1831M    0     0  13.8M      0  0:04:52  0:02:12  0:02:40 20.7M\n",
      " 45 4049M   45 1853M    0     0  13.9M      0  0:04:50  0:02:13  0:02:37 21.0M\n",
      " 45 4049M   45 1859M    0     0  13.8M      0  0:04:53  0:02:14  0:02:39 16.1M\n",
      " 45 4049M   45 1859M    0     0  13.7M      0  0:04:55  0:02:15  0:02:40 12.6M\n",
      " 46 4049M   46 1864M    0     0  13.6M      0  0:04:57  0:02:16  0:02:41 9304k\n",
      " 46 4049M   46 1864M    0     0  13.5M      0  0:04:58  0:02:17  0:02:41 6163k\n",
      " 46 4049M   46 1870M    0     0  13.4M      0  0:05:00  0:02:18  0:02:42 2910k\n",
      " 46 4049M   46 1870M    0     0  13.4M      0  0:05:01  0:02:19  0:02:42 2329k\n",
      " 46 4049M   46 1884M    0     0  13.4M      0  0:05:01  0:02:20  0:02:41 5628k\n",
      " 47 4049M   47 1905M    0     0  13.4M      0  0:05:00  0:02:21  0:02:39 9572k\n",
      " 47 4049M   47 1921M    0     0  13.5M      0  0:04:59  0:02:22  0:02:37 12.4M\n",
      " 47 4049M   47 1939M    0     0  13.5M      0  0:04:58  0:02:23  0:02:35 16.0M\n",
      " 48 4049M   48 1958M    0     0  13.5M      0  0:04:58  0:02:24  0:02:34 18.4M\n",
      " 48 4049M   48 1977M    0     0  13.6M      0  0:04:57  0:02:25  0:02:32 18.5M\n",
      " 49 4049M   49 1999M    0     0  13.6M      0  0:04:56  0:02:26  0:02:30 18.8M\n",
      " 49 4049M   49 2021M    0     0  13.7M      0  0:04:54  0:02:27  0:02:27 20.1M\n",
      " 50 4049M   50 2041M    0     0  13.7M      0  0:04:53  0:02:28  0:02:25 20.3M\n",
      " 50 4049M   50 2044M    0     0  13.7M      0  0:04:55  0:02:29  0:02:26 17.3M\n",
      " 51 4049M   51 2068M    0     0  13.7M      0  0:04:54  0:02:30  0:02:24 18.1M\n",
      " 51 4049M   51 2086M    0     0  13.7M      0  0:04:53  0:02:31  0:02:22 17.0M\n",
      " 51 4049M   51 2100M    0     0  13.8M      0  0:04:53  0:02:32  0:02:21 15.8M\n",
      " 52 4049M   52 2121M    0     0  13.8M      0  0:04:52  0:02:33  0:02:19 16.0M\n",
      " 52 4049M   52 2129M    0     0  13.8M      0  0:04:53  0:02:34  0:02:19 16.9M\n",
      " 52 4049M   52 2132M    0     0  13.7M      0  0:04:54  0:02:35  0:02:19 12.4M\n",
      " 52 4049M   52 2135M    0     0  13.6M      0  0:04:56  0:02:36  0:02:20  9.9M\n",
      " 53 4049M   53 2151M    0     0  13.6M      0  0:04:55  0:02:37  0:02:18 10.0M\n",
      " 53 4049M   53 2172M    0     0  13.7M      0  0:04:54  0:02:38  0:02:16 10.2M\n",
      " 54 4049M   54 2199M    0     0  13.8M      0  0:04:53  0:02:39  0:02:14 13.8M\n",
      " 54 4049M   54 2204M    0     0  13.7M      0  0:04:54  0:02:40  0:02:14 14.8M\n",
      " 54 4049M   54 2210M    0     0  13.6M      0  0:04:55  0:02:41  0:02:14 14.1M\n",
      " 54 4049M   54 2211M    0     0  13.6M      0  0:04:56  0:02:42  0:02:14 12.0M\n",
      " 55 4049M   55 2228M    0     0  13.6M      0  0:04:56  0:02:43  0:02:13 11.0M\n",
      " 55 4049M   55 2251M    0     0  13.7M      0  0:04:55  0:02:44  0:02:11 10.5M\n",
      " 56 4049M   56 2269M    0     0  13.7M      0  0:04:54  0:02:45  0:02:09 12.9M\n",
      " 56 4049M   56 2276M    0     0  13.6M      0  0:04:56  0:02:46  0:02:10 12.9M\n",
      " 56 4049M   56 2276M    0     0  13.6M      0  0:04:57  0:02:47  0:02:10 12.9M\n",
      " 56 4049M   56 2296M    0     0  13.6M      0  0:04:56  0:02:48  0:02:08 13.6M\n",
      " 57 4049M   57 2317M    0     0  13.6M      0  0:04:55  0:02:49  0:02:06 13.0M\n",
      " 57 4049M   57 2340M    0     0  13.7M      0  0:04:54  0:02:50  0:02:04 14.1M\n",
      " 58 4049M   58 2362M    0     0  13.8M      0  0:04:53  0:02:51  0:02:02 18.7M\n",
      " 59 4049M   59 2389M    0     0  13.8M      0  0:04:51  0:02:52  0:01:59 22.6M\n",
      " 59 4049M   59 2408M    0     0  13.9M      0  0:04:51  0:02:53  0:01:58 22.3M\n",
      " 60 4049M   60 2429M    0     0  13.9M      0  0:04:50  0:02:54  0:01:56 22.5M\n",
      " 60 4049M   60 2436M    0     0  13.8M      0  0:04:52  0:02:55  0:01:57 16.8M\n",
      " 60 4049M   60 2436M    0     0  13.7M      0  0:04:53  0:02:56  0:01:57 13.5M\n",
      " 60 4049M   60 2448M    0     0  13.8M      0  0:04:53  0:02:57  0:01:56 11.7M\n",
      " 60 4049M   60 2465M    0     0  13.8M      0  0:04:52  0:02:58  0:01:54 11.5M\n",
      " 61 4049M   61 2491M    0     0  13.9M      0  0:04:51  0:02:59  0:01:52 12.2M\n",
      " 62 4049M   62 2512M    0     0  13.9M      0  0:04:50  0:03:00  0:01:50 17.7M\n",
      " 62 4049M   62 2536M    0     0  14.0M      0  0:04:49  0:03:01  0:01:48 22.1M\n",
      " 63 4049M   63 2554M    0     0  14.0M      0  0:04:48  0:03:02  0:01:46 20.9M\n",
      " 63 4049M   63 2575M    0     0  14.0M      0  0:04:48  0:03:03  0:01:45 21.9M\n",
      " 64 4049M   64 2598M    0     0  14.1M      0  0:04:46  0:03:04  0:01:42 21.5M\n",
      " 64 4049M   64 2606M    0     0  14.0M      0  0:04:48  0:03:05  0:01:43 17.2M\n",
      " 64 4049M   64 2614M    0     0  14.0M      0  0:04:48  0:03:06  0:01:42 15.4M\n",
      " 64 4049M   64 2631M    0     0  14.0M      0  0:04:48  0:03:07  0:01:41 15.5M\n",
      " 65 4049M   65 2652M    0     0  14.0M      0  0:04:47  0:03:08  0:01:39 15.3M\n",
      " 66 4049M   66 2675M    0     0  14.1M      0  0:04:46  0:03:09  0:01:37 15.2M\n",
      " 66 4049M   66 2695M    0     0  14.1M      0  0:04:45  0:03:10  0:01:35 19.4M\n",
      " 67 4049M   67 2715M    0     0  14.2M      0  0:04:45  0:03:11  0:01:34 20.0M\n",
      " 67 4049M   67 2733M    0     0  14.2M      0  0:04:44  0:03:12  0:01:32 20.3M\n",
      " 67 4049M   67 2745M    0     0  14.2M      0  0:04:45  0:03:13  0:01:32 18.4M\n",
      " 68 4049M   68 2758M    0     0  14.2M      0  0:04:45  0:03:14  0:01:31 16.7M\n",
      " 68 4049M   68 2772M    0     0  14.2M      0  0:04:45  0:03:15  0:01:30 15.5M\n",
      " 68 4049M   68 2790M    0     0  14.2M      0  0:04:44  0:03:16  0:01:28 15.0M\n",
      " 69 4049M   69 2802M    0     0  14.2M      0  0:04:44  0:03:17  0:01:27 13.7M\n",
      " 69 4049M   69 2822M    0     0  14.2M      0  0:04:44  0:03:18  0:01:26 15.6M\n",
      " 70 4049M   70 2837M    0     0  14.2M      0  0:04:44  0:03:19  0:01:25 15.7M\n",
      " 70 4049M   70 2856M    0     0  14.2M      0  0:04:43  0:03:20  0:01:23 16.8M\n",
      " 71 4049M   71 2878M    0     0  14.3M      0  0:04:43  0:03:21  0:01:22 17.6M\n",
      " 71 4049M   71 2899M    0     0  14.3M      0  0:04:42  0:03:22  0:01:20 19.3M\n",
      " 72 4049M   72 2922M    0     0  14.3M      0  0:04:41  0:03:23  0:01:18 19.7M\n",
      " 72 4049M   72 2940M    0     0  14.4M      0  0:04:41  0:03:24  0:01:17 20.4M\n",
      " 72 4049M   72 2951M    0     0  14.3M      0  0:04:41  0:03:25  0:01:16 18.9M\n",
      " 73 4049M   73 2972M    0     0  14.4M      0  0:04:40  0:03:26  0:01:14 18.9M\n",
      " 73 4049M   73 2995M    0     0  14.4M      0  0:04:40  0:03:27  0:01:13 19.2M\n",
      " 74 4049M   74 3017M    0     0  14.4M      0  0:04:39  0:03:28  0:01:11 19.1M\n",
      " 74 4049M   74 3030M    0     0  14.4M      0  0:04:40  0:03:29  0:01:11 16.5M\n",
      " 75 4049M   75 3041M    0     0  14.4M      0  0:04:39  0:03:30  0:01:09 17.8M\n",
      " 75 4049M   75 3060M    0     0  14.4M      0  0:04:39  0:03:31  0:01:08 17.4M\n",
      " 76 4049M   76 3079M    0     0  14.5M      0  0:04:39  0:03:32  0:01:07 16.8M\n",
      " 76 4049M   76 3102M    0     0  14.5M      0  0:04:38  0:03:33  0:01:05 16.9M\n",
      " 77 4049M   77 3124M    0     0  14.5M      0  0:04:37  0:03:34  0:01:03 20.7M\n",
      " 77 4049M   77 3140M    0     0  14.5M      0  0:04:37  0:03:35  0:01:02 19.1M\n",
      " 77 4049M   77 3157M    0     0  14.6M      0  0:04:37  0:03:36  0:01:01 19.5M\n",
      " 78 4049M   78 3180M    0     0  14.6M      0  0:04:36  0:03:37  0:00:59 20.1M\n",
      " 78 4049M   78 3194M    0     0  14.6M      0  0:04:36  0:03:38  0:00:58 18.5M\n",
      " 79 4049M   79 3214M    0     0  14.6M      0  0:04:36  0:03:39  0:00:57 17.9M\n",
      " 79 4049M   79 3231M    0     0  14.6M      0  0:04:36  0:03:40  0:00:56 16.7M\n",
      " 79 4049M   79 3235M    0     0  14.6M      0  0:04:37  0:03:41  0:00:56 14.9M\n",
      " 80 4049M   80 3254M    0     0  14.6M      0  0:04:36  0:03:42  0:00:54 14.8M\n",
      " 80 4049M   80 3278M    0     0  14.6M      0  0:04:35  0:03:43  0:00:52 16.7M\n",
      " 81 4049M   81 3301M    0     0  14.7M      0  0:04:34  0:03:44  0:00:50 17.4M\n",
      " 81 4049M   81 3318M    0     0  14.7M      0  0:04:34  0:03:45  0:00:49 20.0M\n",
      " 82 4049M   82 3342M    0     0  14.7M      0  0:04:34  0:03:46  0:00:48 22.1M\n",
      " 83 4049M   83 3365M    0     0  14.8M      0  0:04:33  0:03:47  0:00:46 22.1M\n",
      " 83 4049M   83 3387M    0     0  14.8M      0  0:04:32  0:03:48  0:00:44 21.7M\n",
      " 84 4049M   84 3406M    0     0  14.8M      0  0:04:32  0:03:49  0:00:43 20.9M\n",
      " 84 4049M   84 3427M    0     0  14.8M      0  0:04:31  0:03:50  0:00:41 21.7M\n",
      " 85 4049M   85 3450M    0     0  14.9M      0  0:04:31  0:03:51  0:00:40 21.7M\n",
      " 85 4049M   85 3474M    0     0  14.9M      0  0:04:30  0:03:52  0:00:38 21.7M\n",
      " 86 4049M   86 3495M    0     0  14.9M      0  0:04:30  0:03:53  0:00:37 21.5M\n",
      " 86 4049M   86 3517M    0     0  15.0M      0  0:04:29  0:03:54  0:00:35 22.2M\n",
      " 87 4049M   87 3537M    0     0  15.0M      0  0:04:29  0:03:55  0:00:34 21.9M\n",
      " 87 4049M   87 3558M    0     0  15.0M      0  0:04:28  0:03:56  0:00:32 21.4M\n",
      " 88 4049M   88 3574M    0     0  15.0M      0  0:04:29  0:03:58  0:00:31 17.0M\n",
      " 88 4049M   88 3574M    0     0  14.9M      0  0:04:30  0:03:58  0:00:32 14.2M\n",
      " 88 4049M   88 3586M    0     0  14.9M      0  0:04:30  0:03:59  0:00:31 13.8M\n",
      " 88 4049M   88 3603M    0     0  15.0M      0  0:04:29  0:04:00  0:00:29 13.1M\n",
      " 89 4049M   89 3624M    0     0  15.0M      0  0:04:29  0:04:01  0:00:28 13.2M\n",
      " 90 4049M   90 3646M    0     0  15.0M      0  0:04:28  0:04:02  0:00:26 17.5M\n",
      " 90 4049M   90 3665M    0     0  15.0M      0  0:04:28  0:04:03  0:00:25 20.4M\n",
      " 91 4049M   91 3686M    0     0  15.0M      0  0:04:28  0:04:04  0:00:24 19.9M\n",
      " 91 4049M   91 3712M    0     0  15.1M      0  0:04:27  0:04:05  0:00:22 21.8M\n",
      " 92 4049M   92 3736M    0     0  15.1M      0  0:04:26  0:04:06  0:00:20 22.4M\n",
      " 92 4049M   92 3753M    0     0  15.1M      0  0:04:27  0:04:07  0:00:20 19.0M\n",
      " 92 4049M   92 3758M    0     0  15.1M      0  0:04:27  0:04:08  0:00:19 18.4M\n",
      " 93 4049M   93 3781M    0     0  15.1M      0  0:04:26  0:04:09  0:00:17 18.8M\n",
      " 93 4049M   93 3796M    0     0  15.1M      0  0:04:26  0:04:10  0:00:16 16.7M\n",
      " 94 4049M   94 3812M    0     0  15.1M      0  0:04:26  0:04:11  0:00:15 15.1M\n",
      " 94 4049M   94 3832M    0     0  15.1M      0  0:04:26  0:04:12  0:00:14 18.0M\n",
      " 95 4049M   95 3856M    0     0  15.2M      0  0:04:25  0:04:13  0:00:12 19.7M\n",
      " 95 4049M   95 3874M    0     0  15.2M      0  0:04:25  0:04:14  0:00:11 18.6M\n",
      " 96 4049M   96 3896M    0     0  15.2M      0  0:04:25  0:04:15  0:00:10 20.0M\n",
      " 96 4049M   96 3919M    0     0  15.3M      0  0:04:24  0:04:16  0:00:08 21.4M\n",
      " 97 4049M   97 3941M    0     0  15.3M      0  0:04:24  0:04:17  0:00:07 21.7M\n",
      " 97 4049M   97 3962M    0     0  15.3M      0  0:04:23  0:04:18  0:00:05 21.1M\n",
      " 98 4049M   98 3985M    0     0  15.3M      0  0:04:23  0:04:19  0:00:04 22.3M\n",
      " 98 4049M   98 4004M    0     0  15.3M      0  0:04:23  0:04:20  0:00:03 21.5M\n",
      " 99 4049M   99 4021M    0     0  15.3M      0  0:04:22  0:04:21  0:00:01 20.4M\n",
      " 99 4049M   99 4048M    0     0  15.4M      0  0:04:22  0:04:22 --:--:-- 21.4M\n",
      "100 4049M  100 4049M    0     0  15.4M      0  0:04:22  0:04:22 --:--:-- 21.4M\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data/pv/2020\", exist_ok=True)\n",
    "    os.makedirs(\"data/satellite-hrv/2020\", exist_ok=True)\n",
    "\n",
    "    !curl -L https://huggingface.co/datasets/climatehackai/climatehackai-2023/resolve/main/pv/metadata.csv --output data/pv/metadata.csv\n",
    "    !curl -L https://huggingface.co/datasets/climatehackai/climatehackai-2023/resolve/main/pv/2020/7.parquet --output data/pv/2020/7.parquet\n",
    "    !curl -L https://huggingface.co/datasets/climatehackai/climatehackai-2023/resolve/main/satellite-hrv/2020/7.zarr.zip --output data/satellite-hrv/2020/7.zarr.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th>ss_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2020-07-01 00:00:00+00:00</th>\n",
       "      <th>2607</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2020-07-31 23:55:00+00:00</th>\n",
       "      <th>27062</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27063</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27064</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27065</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27066</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7827134 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 power\n",
       "timestamp                 ss_id       \n",
       "2020-07-01 00:00:00+00:00 2607     0.0\n",
       "                          2626     0.0\n",
       "                          2631     0.0\n",
       "                          2657     0.0\n",
       "                          2729     0.0\n",
       "...                                ...\n",
       "2020-07-31 23:55:00+00:00 27062    0.0\n",
       "                          27063    0.0\n",
       "                          27064    0.0\n",
       "                          27065    0.0\n",
       "                          27066    0.0\n",
       "\n",
       "[7827134 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pv = pd.read_parquet(\"data/pv/2020/7.parquet\").drop(\"generation_wh\", axis=1)\n",
    "\n",
    "pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unrecognized engine zarr must be one of: ['scipy', 'store']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m hrv \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/satellite-hrv/2020/7.zarr.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzarr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m hrv\n",
      "File \u001b[1;32mc:\\Users\\nikpr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xarray\\backends\\api.py:559\u001b[0m, in \u001b[0;36mopen_dataset\u001b[1;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_array_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    557\u001b[0m     from_array_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 559\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    561\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[0;32m    562\u001b[0m     decode_cf,\n\u001b[0;32m    563\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    569\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[0;32m    570\u001b[0m )\n\u001b[0;32m    572\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\nikpr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xarray\\backends\\plugins.py:205\u001b[0m, in \u001b[0;36mget_backend\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m    203\u001b[0m     engines \u001b[38;5;241m=\u001b[39m list_engines()\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m engines:\n\u001b[1;32m--> 205\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    206\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be one of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(engines)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    207\u001b[0m         )\n\u001b[0;32m    208\u001b[0m     backend \u001b[38;5;241m=\u001b[39m engines[engine]\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(engine, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(engine, BackendEntrypoint):\n",
      "\u001b[1;31mValueError\u001b[0m: unrecognized engine zarr must be one of: ['scipy', 'store']"
     ]
    }
   ],
   "source": [
    "hrv = xr.open_dataset(\n",
    "    \"data/satellite-hrv/2020/7.zarr.zip\", engine=\"zarr\", chunks=\"auto\"\n",
    ")\n",
    "\n",
    "hrv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the challenge, you can make use of satellite imagery, numerical weather prediction and air quality forecast data in a `[128, 128]` region centred on each solar PV site. In order to help you out, we have pre-computed the indices corresponding to each solar PV site and included them in `indices.json`, which we can load directly. For more information, take a look at the [challenge page](https://doxaai.com/competition/climatehackai-2023).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"indices.json\") as f:\n",
    "    site_locations = {\n",
    "        data_source: {\n",
    "            int(site): (int(location[0]), int(location[1]))\n",
    "            for site, location in locations.items()\n",
    "        }\n",
    "        for data_source, locations in json.load(f).items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a PyTorch Dataset\n",
    "\n",
    "To get started, we will define a simple `IterableDataset` that shows how to slice into the PV and HRV data using `pandas` and `xarray`, respectively. You will have to modify this if you wish to incorporate non-HRV data, weather forecasts and air quality forecasts into your training regimen. If you have any questions, feel free to ask on the [ClimateHack.AI Community Discord server](https://discord.gg/HTTQ8AFjJp)!\n",
    "\n",
    "**Note**: `site_locations` contains indices for the non-HRV, weather forecast and air quality forecast data as well as for the HRV data!\n",
    "\n",
    "There are many more advanced strategies you could implement to load data in training, particularly if you want to pre-prepare training batches in advance or use multiple workers to improve data loading times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChallengeDataset(IterableDataset):\n",
    "    def __init__(self, pv, hrv, site_locations, sites=None):\n",
    "        self.pv = pv\n",
    "        self.hrv = hrv\n",
    "        self._site_locations = site_locations\n",
    "        self._sites = sites if sites else list(site_locations[\"hrv\"].keys())\n",
    "\n",
    "    def _get_image_times(self):\n",
    "        min_date = datetime(2020, 7, 1)\n",
    "        max_date = datetime(2020, 7, 30)\n",
    "\n",
    "        start_time = time(8)\n",
    "        end_time = time(17)\n",
    "\n",
    "        date = min_date\n",
    "        while date <= max_date:\n",
    "            current_time = datetime.combine(date, start_time)\n",
    "            while current_time.time() < end_time:\n",
    "                if current_time:\n",
    "                    yield current_time\n",
    "\n",
    "                current_time += timedelta(minutes=60)\n",
    "\n",
    "            date += timedelta(days=1)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for time in self._get_image_times():\n",
    "            first_hour = slice(str(time), str(time + timedelta(minutes=55)))\n",
    "\n",
    "            pv_features = pv.xs(first_hour, drop_level=False)  # type: ignore\n",
    "            pv_targets = pv.xs(\n",
    "                slice(  # type: ignore\n",
    "                    str(time + timedelta(hours=1)),\n",
    "                    str(time + timedelta(hours=4, minutes=55)),\n",
    "                ),\n",
    "                drop_level=False,\n",
    "            )\n",
    "\n",
    "            hrv_data = self.hrv[\"data\"].sel(time=first_hour).to_numpy()\n",
    "\n",
    "            for site in self._sites:\n",
    "                try:\n",
    "                    # Get solar PV features and targets\n",
    "                    site_features = pv_features.xs(site, level=1).to_numpy().squeeze(-1)\n",
    "                    site_targets = pv_targets.xs(site, level=1).to_numpy().squeeze(-1)\n",
    "                    assert site_features.shape == (12,) and site_targets.shape == (48,)\n",
    "\n",
    "                    # Get a 128x128 HRV crop centred on the site over the previous hour\n",
    "                    x, y = self._site_locations[\"hrv\"][site]\n",
    "                    hrv_features = hrv_data[:, y - 64 : y + 64, x - 64 : x + 64, 0]\n",
    "                    assert hrv_features.shape == (12, 128, 128)\n",
    "\n",
    "                    # How might you adapt this for the non-HRV, weather and aerosol data?\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                yield site_features, hrv_features, site_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a model\n",
    "\n",
    "In order to make a PyTorch-based submission to the DOXA AI platform, you need to upload both the code defining your model in addition to your trained model weights (and some code to run your model). As a result, if you want to experiment with different model architectures using this notebook, you will need to edit the model in `submission/model.py` and re-import it here.\n",
    "\n",
    "Here is the small convolutional neural network you are initially given in `submission/model.py`. You will absolutely be able to improve upon this!\n",
    "\n",
    "```py\n",
    "#########################################\n",
    "#       Improve this basic model!       #\n",
    "#########################################\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=48, out_channels=96, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(in_channels=96, out_channels=192, kernel_size=3)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear1 = nn.Linear(6924, 48)\n",
    "\n",
    "    def forward(self, pv, hrv):\n",
    "        x = torch.relu(self.pool(self.conv1(hrv)))\n",
    "        x = torch.relu(self.pool(self.conv2(x)))\n",
    "        x = torch.relu(self.pool(self.conv3(x)))\n",
    "        x = torch.relu(self.pool(self.conv4(x)))\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = torch.concat((x, pv), dim=-1)\n",
    "\n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model defined in `submission/model.py`\n",
    "\n",
    "from submission.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(Model(), input_size=[(1, 12), (1, 12, 128, 128)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset = ChallengeDataset(pv, hrv, site_locations=site_locations)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimiser = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    count = 0\n",
    "    for i, (pv_features, hrv_features, pv_targets) in enumerate(dataloader):\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        predictions = model(\n",
    "            pv_features.to(device, dtype=torch.float),\n",
    "            hrv_features.to(device, dtype=torch.float),\n",
    "        )\n",
    "\n",
    "        loss = criterion(predictions, pv_targets.to(device, dtype=torch.float))\n",
    "        loss.backward()\n",
    "\n",
    "        optimiser.step()\n",
    "\n",
    "        size = int(pv_targets.size(0))\n",
    "        running_loss += float(loss) * size\n",
    "        count += size\n",
    "\n",
    "        if i % 200 == 199:\n",
    "            print(f\"Epoch {epoch + 1}, {i + 1}: {running_loss / count}\")\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: {running_loss / count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model\n",
    "torch.save(model.state_dict(), \"submission/model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting to the DOXA AI platform\n",
    "\n",
    "Congratulations &ndash; **you have trained your first model for ClimateHack.AI 2023**! ðŸ¥³\n",
    "\n",
    "Why not try making a submission to the platform?\n",
    "\n",
    "First, make sure you have enrolled for the competition on the [ClimateHack.AI 2023 competition page](https://doxaai.com/competition/climatehackai-2023). You will need to be signed in with a DOXA AI account registered with your university email address so that we can verify your eligibility.\n",
    "\n",
    "You can then sign in with the CLI using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!doxa login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can upload your submission to the platform by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!doxa upload submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything went well, you will soon appear on the [competition scoreboard](https://doxaai.com/competition/climatehackai-2023/scoreboard) once your model has been evaluated! ðŸ˜Ž"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Well done for reaching the end of this Jupyter notebook! By now, you will have loaded and explored the data, trained a basic model, and joined other competition participants on the [competition scoreboard](https://doxaai.com/competition/climatehackai-2023/scoreboard)!\n",
    "\n",
    "To get started, we used a very simple model architecture, but this model most likely does not have a sufficiently rich representation to properly solve our problem. How might you be able to improve on this? Which model architectures would be best suited to this problem? Would you want to train a model from scratch, as we have done here, or possibly fine-tune a pre-trained computer vision model? Check out the resources on the [competition page](https://doxaai.com/competition/climatehackai-2023) for ideas on where to go from here.\n",
    "\n",
    "Additionally, we only used historical PV and HRV data, but perhaps you might be able to get more mileage out of the other data sources available to you, such as non-HRV satellite imagery, the DWD weather forecast data or even the aerosol data. If you do decide to incorporate more data, what **data engineering** work would you have to perform so that you can train effectively on a large quantity of data?\n",
    "\n",
    "**We want to hear about your approaches**! If you develop anything interesting, let us know on the [ClimateHack.AI Community Discord server](https://discord.gg/HTTQ8AFjJp) and start a conversation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
